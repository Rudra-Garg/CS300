name: CS300
services:
  # cloud:
  #   build: ./cloud
  #   networks:
  #     - cloud_proxy_net
  #   cap_add:
  #     - NET_ADMIN
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost/health"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 60s
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   volumes:
  #     - ./logs/cloud:/var/log/nginx

  # proxy:
  #   build: ./proxy
  #   networks:
  #     - cloud_proxy_net
  #     - proxy_gateways_net
  #   cap_add:
  #     - NET_ADMIN
  #   ports:
  #     - "9090:9090"
  #   depends_on:
  #     gateway1:
  #       condition: service_healthy
  #     gateway2:
  #       condition: service_healthy
  #   environment:
  #     - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
  #     - LATENCY_PROXY_TO_CLOUD=${LATENCY_PROXY_TO_CLOUD:-0ms}
  #     # Pass jitter/loss if using them in entrypoint.sh
  #     - JITTER_PROXY_TO_CLOUD=${JITTER_PROXY_TO_CLOUD:-}
  #     - LOSS_PROXY_TO_CLOUD=${LOSS_PROXY_TO_CLOUD:-}
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost/health"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 60s
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   volumes:
  #     - ./logs/proxy:/var/log/nginx
  #     - ./config:/app/config

  cloud_py: 
    build:
      context: .
      dockerfile: cloud_py/Dockerfile
    networks:
      - cloud_proxy_net # Connects only to the proxy network
    cap_add:
      - NET_ADMIN # Keep if needed for potential future network manipulation
    ports:
      - "8081:8000" # Expose cloud service on host port 8081 (internal 8000)
    deploy:
      resources:
        limits:
          cpus: '1' # Example: Give cloud more resources
          memory: 1G
    environment:
      - PYTHONUNBUFFERED=1
      - CLOUD_PROCESSING_LEVEL=${CLOUD_PROCESSING_LEVEL:-3}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s # Should start faster than Nginx
    logging:
      driver: "json-file"
      options:
          max-size: "10m"
          max-file: "3"

  proxy_py: # Renamed service for clarity
    build:
      context: .
      dockerfile: proxy_py/Dockerfile
    networks:
      - cloud_proxy_net    # Connects up to cloud
      - proxy_gateways_net # Connects down to gateways
    depends_on:
      cloud_py:
        condition: service_healthy
    cap_add:
      - NET_ADMIN 
    ports:
      - "8080:8000" # Expose proxy on host port 8080 (internal 8000)
    deploy: 
      resources:
        limits:
          cpus: '0.1' 
          memory: 512M 
    environment:
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_PROXY_TO_CLOUD=${LATENCY_PROXY_TO_CLOUD:-0ms}
      - JITTER_PROXY_TO_CLOUD=${JITTER_PROXY_TO_CLOUD:-} # Pass empty if unset in .env
      - LOSS_PROXY_TO_CLOUD=${LOSS_PROXY_TO_CLOUD:-}
      - PYTHONUNBUFFERED=1
      - PROXY_PROCESSING_LEVEL=${PROXY_PROCESSING_LEVEL:-3}
      - CLOUD_URL=${CLOUD_URL:-http://cloud_py:8000}

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
          max-size: "10m"
          max-file: "3"
    volumes:
      - ./logs/proxy:/app/logs
      - ./config:/app/config


  gateway1:
    build:
      context: . 
      dockerfile: gateway/Dockerfile
    networks:
      - proxy_gateways_net
      - gateway1_mobiles_net
    cap_add:
      - NET_ADMIN
    ports:
      - "9091:8000" 
    depends_on:
      proxy_py:
          condition: service_healthy
    deploy: 
      resources:
        limits:
          cpus: '0.1'
          memory: 512M 
    environment:
      - PROXY_URL=http://proxy_py:8000/
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_GATEWAY_TO_PROXY=${LATENCY_GATEWAY_TO_PROXY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_GATEWAY_TO_PROXY=${JITTER_GATEWAY_TO_PROXY:-}
      - LOSS_GATEWAY_TO_PROXY=${LOSS_GATEWAY_TO_PROXY:-}
      # Pass other necessary env vars if any (like PYTHONUNBUFFERED)
      - PYTHONUNBUFFERED=1
      - GATEWAY_PROCESSING_LEVEL=${GATEWAY_PROCESSING_LEVEL:-2}

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs/edge1:/app/logs
      - ./config:/app/config

  gateway2:
    build:
      context: . 
      dockerfile: gateway/Dockerfile
    networks:
      - proxy_gateways_net
      - gateway2_mobiles_net
    cap_add:
      - NET_ADMIN
    ports:
      - "9092:8000"  
    depends_on:
      proxy_py:
          condition: service_healthy
    deploy: 
      resources:
        limits:
          cpus: '0.1' 
          memory: 512M 
    environment:
      - PROXY_URL=http://proxy_py:8000/
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_GATEWAY_TO_PROXY=${LATENCY_GATEWAY_TO_PROXY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_GATEWAY_TO_PROXY=${JITTER_GATEWAY_TO_PROXY:-}
      - LOSS_GATEWAY_TO_PROXY=${LOSS_GATEWAY_TO_PROXY:-}
      # Pass other necessary env vars if any (like PYTHONUNBUFFERED)
      - PYTHONUNBUFFERED=1
      - GATEWAY_PROCESSING_LEVEL=${GATEWAY_PROCESSING_LEVEL:-2}

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs/edge2:/app/logs
      - ./config:/app/config

  mobile1_1:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway1_mobiles_net
    # MERGE environment variables
    environment:
      - GATEWAY=gateway1 
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}

    cap_add:
      - NET_ADMIN
    ports:
      - "9093:9090"
    deploy: 
      resources:
        limits:
          cpus: '0.05' 
          memory: 256M 
    depends_on:
      gateway1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs/mobile1_1:/app/logs
      - ./config:/app/config

  mobile1_2:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway1_mobiles_net
    environment:
      - GATEWAY=gateway1 
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      # - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      # - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      # - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9094:9090" 
    deploy: 
      resources:
        limits:
          cpus: '0.05' 
          memory: 256M 
    depends_on:
      gateway1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mobile1_3:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway1_mobiles_net
    environment:
      - GATEWAY=gateway1 
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      # - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      # - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      # - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9096:9090" 
    deploy:
      resources:
        limits:
          cpus: '0.05' 
          memory: 256M 
    depends_on:
      gateway1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mobile1_4:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway1_mobiles_net
    # MERGE environment variables
    environment:
      - GATEWAY=gateway1 # Keep existing ones
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      # - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      # - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      # - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9097:9090" 
    deploy: # <-- ADD THIS SECTION (Optional)
      resources:
        limits:
          cpus: '0.05' # Example: Limit mobile to 20% of a core
          memory: 256M # Example: Limit mobile RAM
    depends_on:
      gateway1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mobile2_1:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway2_mobiles_net
    # MERGE environment variables
    environment:
      - GATEWAY=gateway2 # Keep existing ones
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      # - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      # - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      # - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9098:9090" 
    deploy: # <-- ADD THIS SECTION (Optional)
      resources:
        limits:
          cpus: '0.05' # Example: Limit mobile to 20% of a core
          memory: 256M # Example: Limit mobile RAM
    depends_on:
      gateway2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mobile2_2:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway2_mobiles_net
    # MERGE environment variables
    environment:
      - GATEWAY=gateway2 # Keep existing ones
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      # - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      # - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      # - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9099:9090" 
    deploy: # <-- ADD THIS SECTION (Optional)
      resources:
        limits:
          cpus: '0.05' # Example: Limit mobile to 20% of a core
          memory: 256M # Example: Limit mobile RAM
    depends_on:
      gateway2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mobile2_3:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway2_mobiles_net
    # MERGE environment variables
    environment:
      - GATEWAY=gateway2 # Keep existing ones
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9100:9090" 
    deploy: # <-- ADD THIS SECTION (Optional)
      resources:
        limits:
          cpus: '0.05' # Example: Limit mobile to 20% of a core
          memory: 256M # Example: Limit mobile RAM
    depends_on:
      gateway2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mobile2_4:
    build:
      context: . 
      dockerfile: mobile/Dockerfile
    networks:
      - gateway2_mobiles_net
    # MERGE environment variables
    environment:
      - GATEWAY=gateway2 # Keep existing ones
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add the latency variables
      - ENABLE_LATENCY=${ENABLE_LATENCY:-false}
      - LATENCY_MOBILE_TO_GATEWAY=${LATENCY_MOBILE_TO_GATEWAY:-0ms}
      # Pass jitter/loss if using them in entrypoint.sh
      - JITTER_MOBILE_TO_GATEWAY=${JITTER_MOBILE_TO_GATEWAY:-}
      - LOSS_MOBILE_TO_GATEWAY=${LOSS_MOBILE_TO_GATEWAY:-}
      # Add the placement strategy and load threshold variables
      # - PLACEMENT_STRATEGY=${PLACEMENT_STRATEGY:-ewmp}
      # - MOBILE_CPU_LIMIT=${MOBILE_CPU_LIMIT:-0.2}
      # - MOBILE_LOAD_THRESHOLD=${MOBILE_LOAD_THRESHOLD:-0.8}
      - MOBILE_PROCESSING_LEVEL=${MOBILE_PROCESSING_LEVEL:-1}
    cap_add:
      - NET_ADMIN
    ports:
      - "9101:9090" 
    deploy: # <-- ADD THIS SECTION (Optional)
      resources:
        limits:
          cpus: '0.05' # Example: Limit mobile to 20% of a core
          memory: 256M # Example: Limit mobile RAM
    depends_on:
      gateway2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'  # Add this line
    ports:
      - "9095:9090"
    networks:
      - monitoring_net
      - cloud_proxy_net
      - proxy_gateways_net
      - gateway1_mobiles_net
      - gateway2_mobiles_net
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./config/grafana.ini:/etc/grafana/grafana.ini:ro
      - ./config/grafana-provisioning:/etc/grafana/provisioning:ro  # Add this line
      - ./config/grafana-dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - monitoring_net
    depends_on:
      - prometheus
      - loki
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    restart: unless-stopped

  loki:
    image: grafana/loki:latest 
    volumes:
      - ./config/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - monitoring_net 
    logging:
      driver: "json-file"
      options: { max-size: "10m", max-file: "3" }
    restart: unless-stopped

  promtail:
    image: grafana/promtail:latest 
    volumes:
      - ./config/promtail-config.yaml:/etc/promtail/config.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro 
      - promtail_positions:/tmp/positions 
    command: -config.file=/etc/promtail/config.yml
    networks:
      - monitoring_net 
    logging:
      driver: "json-file"
      options: { max-size: "10m", max-file: "3" }
    restart: unless-stopped

networks:
  cloud_proxy_net:
  proxy_gateways_net:
  gateway1_mobiles_net:
  gateway2_mobiles_net:
  monitoring_net:

volumes:
  prometheus_data:
  grafana_data:
  loki_data:
  promtail_positions: